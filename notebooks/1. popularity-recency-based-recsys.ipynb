{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Popularity/Recency on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "gather": {
     "logged": 1745761833630
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "# ── CONFIG ────────────────────────────────────────────────────\n",
    "TRAIN_PATH        = \"../datasets/train_clicks.parquet\"\n",
    "VAL_PATH          = \"../datasets/valid_clicks.parquet\"\n",
    "TEST_PATH         = \"../datasets/test_clicks.parquet\"\n",
    "META_PATH         = \"../datasets/articles_metadata.csv\"   # or your parquet copy\n",
    "HALF_LIFE_DAYS    = [100_000, 3, 6., 8.]\n",
    "BETA_VALUES       = [0.0, 0.001, 5., 7.]\n",
    "FRESH_WINDOW_DAYS = 1\n",
    "TOP_M             = 500\n",
    "RECALL_K          = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "gather": {
     "logged": 1745761795574
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (2857109, 12), Val: (65536, 12), Test: (65536, 12)\n"
     ]
    }
   ],
   "source": [
    "# 1) Load train / val / test\n",
    "train_df = pd.read_parquet(TRAIN_PATH)\n",
    "val_df   = pd.read_parquet(VAL_PATH)\n",
    "test_df  = pd.read_parquet(TEST_PATH)\n",
    "\n",
    "# ensure timestamps are datetime\n",
    "for df in (train_df, val_df, test_df):\n",
    "    df[\"click_timestamp\"] = pd.to_datetime(df[\"click_timestamp\"], unit=\"ms\")\n",
    "\n",
    "print(f\"Train: {train_df.shape}, Val: {val_df.shape}, Test: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "gather": {
     "logged": 1745761840099
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(364047, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "      <th>publisher_id</th>\n",
       "      <th>words_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-13 05:53:39</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-07-14 12:45:36</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-22 00:35:06</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-19 17:11:53</td>\n",
       "      <td>0</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03 13:06:11</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id  category_id       created_at_ts  publisher_id  words_count\n",
       "0           0            0 2017-12-13 05:53:39             0          168\n",
       "1           1            1 2014-07-14 12:45:36             0          189\n",
       "2           2            1 2014-08-22 00:35:06             0          250\n",
       "3           3            1 2014-08-19 17:11:53             0          230\n",
       "4           4            1 2014-08-03 13:06:11             0          162"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Load metadata\n",
    "dtypes = {\n",
    "        \"article_id\": \"uint32\",\n",
    "        \"category_id\": \"uint16\",\n",
    "        \"publisher_id\": \"uint8\",\n",
    "        \"words_count\": \"uint16\"\n",
    "    }\n",
    "\n",
    "articles = pd.read_csv(META_PATH,dtype=dtypes)\n",
    "\n",
    "articles[\"created_at_ts\"] = pd.to_datetime(articles[\"created_at_ts\"], unit=\"ms\")\n",
    "print(articles.shape)\n",
    "articles.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "gather": {
     "logged": 1745762736320
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_scores(train_df, articles, half_life_days, beta, fresh_window_days, top_m=500):\n",
    "    # 1) global reference time\n",
    "    now = train_df[\"click_timestamp\"].max()\n",
    "    # 2) decay constant (per second)\n",
    "    λ = np.log(2) / pd.Timedelta(days=half_life_days).total_seconds()\n",
    "    # 3) per-click weights\n",
    "    ages    = (now - train_df[\"click_timestamp\"]).dt.total_seconds()\n",
    "    weights = np.exp(-λ * ages)\n",
    "    # 4) aggregate per article\n",
    "    pop = (\n",
    "        train_df.assign(weight=weights)\n",
    "                .groupby(\"click_article_id\")[\"weight\"]\n",
    "                .sum()\n",
    "                .rename(\"pop_score\")\n",
    "                .to_frame()\n",
    "    )\n",
    "    # 5) join publication times\n",
    "    pop = pop.join(\n",
    "        articles.set_index(\"article_id\")[[\"created_at_ts\"]],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    # 6) apply freshness boost\n",
    "    is_fresh = (now - pop[\"created_at_ts\"]) <= pd.Timedelta(days=fresh_window_days)\n",
    "    pop[\"final_score\"] = pop[\"pop_score\"] * (1 + beta * is_fresh.astype(float))\n",
    "    # 7) build cleaned candidates DF\n",
    "    top_series = pop[\"final_score\"].nlargest(top_m)\n",
    "    cands = pd.DataFrame({\n",
    "        \"article_id\": top_series.index.astype(int),\n",
    "        \"final_score\": top_series.values\n",
    "    })\n",
    "    return cands\n",
    "\n",
    "\n",
    "def recall_at_k(cands, articles, holdout_df, K):\n",
    "    # pull publication dates\n",
    "    pub_dates = articles.set_index(\"article_id\")[\"created_at_ts\"].to_dict()\n",
    "    assert \"article_id\" in cands.columns, \"cands missing article_id\"\n",
    "    \n",
    "    # user → cutoff map\n",
    "    user_cutoff = holdout_df.set_index(\"user_id\")[\"click_timestamp\"].to_dict()\n",
    "    art_ids = cands[\"article_id\"].tolist()\n",
    "    hits = []\n",
    "    for _, row in holdout_df.iterrows():\n",
    "        uid, true_a = row[\"user_id\"], row[\"click_article_id\"]\n",
    "        cutoff = user_cutoff[uid]\n",
    "        # keep only articles published ≤ cutoff\n",
    "        valid = [a for a in art_ids if pub_dates.get(a, pd.Timestamp(0)) <= cutoff]\n",
    "        topk  = valid[:K]\n",
    "        hits.append(true_a in topk)\n",
    "    return np.mean(hits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "gather": {
     "logged": 1745763798276
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry 1/16: h=100000, β=0.0\n",
      " → Recall@10: 0.0214\n",
      "\n",
      "Entry 2/16: h=100000, β=0.001\n",
      " → Recall@10: 0.0214\n",
      "\n",
      "Entry 3/16: h=100000, β=5.0\n",
      " → Recall@10: 0.0214\n",
      "\n",
      "Entry 4/16: h=100000, β=7.0\n",
      " → Recall@10: 0.0214\n",
      "\n",
      "Entry 5/16: h=3, β=0.0\n",
      " → Recall@10: 0.1470\n",
      "\n",
      "Entry 6/16: h=3, β=0.001\n",
      " → Recall@10: 0.1470\n",
      "\n",
      "Entry 7/16: h=3, β=5.0\n",
      " → Recall@10: 0.1470\n",
      "\n",
      "Entry 8/16: h=3, β=7.0\n",
      " → Recall@10: 0.1470\n",
      "\n",
      "Entry 9/16: h=6.0, β=0.0\n",
      " → Recall@10: 0.0894\n",
      "\n",
      "Entry 10/16: h=6.0, β=0.001\n",
      " → Recall@10: 0.0894\n",
      "\n",
      "Entry 11/16: h=6.0, β=5.0\n",
      " → Recall@10: 0.0894\n",
      "\n",
      "Entry 12/16: h=6.0, β=7.0\n",
      " → Recall@10: 0.0894\n",
      "\n",
      "Entry 13/16: h=8.0, β=0.0\n",
      " → Recall@10: 0.0571\n",
      "\n",
      "Entry 14/16: h=8.0, β=0.001\n",
      " → Recall@10: 0.0571\n",
      "\n",
      "Entry 15/16: h=8.0, β=5.0\n",
      " → Recall@10: 0.0571\n",
      "\n",
      "Entry 16/16: h=8.0, β=7.0\n",
      " → Recall@10: 0.0571\n",
      "\n",
      "Best hyperparameters:\n",
      " half_life_days    3.000000\n",
      "beta              0.000000\n",
      "recall@10         0.147034\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "results = []\n",
    "for counter, (h, beta) in enumerate(product(HALF_LIFE_DAYS, BETA_VALUES)):\n",
    "    print(f\"Entry {counter+1}/{len(HALF_LIFE_DAYS)*len(BETA_VALUES)}: h={h}, β={beta}\")\n",
    "    cands = compute_scores(train_df, articles, h, beta, FRESH_WINDOW_DAYS, top_m=TOP_M)\n",
    "    r = recall_at_k(cands, articles, val_df, RECALL_K)\n",
    "    results.append({\n",
    "        \"half_life_days\": h,\n",
    "        \"beta\": beta,\n",
    "        f\"recall@{RECALL_K}\": r\n",
    "    })\n",
    "    print(f\" → Recall@{RECALL_K}: {r:.4f}\\n\")\n",
    "\n",
    "df_res = pd.DataFrame(results)\n",
    "best = df_res.sort_values(f\"recall@{RECALL_K}\", ascending=False).iloc[0]\n",
    "print(\"Best hyperparameters:\\n\", best)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 3.2 Combine training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "gather": {
     "logged": 1745764109781
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cell: Final Evaluation on Test Set\n",
    "\n",
    "# 1) Load splits (if not already in memory)\n",
    "train_df = pd.read_parquet(\"../datasets/train_clicks.parquet\")\n",
    "val_df   = pd.read_parquet(\"../datasets/valid_clicks.parquet\")\n",
    "test_df  = pd.read_parquet(\"../datasets/test_clicks.parquet\")\n",
    "\n",
    "# Ensure timestamps are datetime\n",
    "for df in (train_df, val_df, test_df):\n",
    "    df[\"click_timestamp\"] = pd.to_datetime(df[\"click_timestamp\"], unit=\"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "gather": {
     "logged": 1745764140699
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2) Load metadata (if not already in memory)\n",
    "articles = pd.read_csv(\n",
    "    \"../datasets/articles_metadata.csv\",\n",
    "    dtype={\n",
    "        \"article_id\": \"uint32\",\n",
    "        \"category_id\": \"uint16\",\n",
    "        \"publisher_id\": \"uint8\",\n",
    "        \"words_count\": \"uint16\"\n",
    "    }\n",
    ")\n",
    "articles[\"created_at_ts\"] = pd.to_datetime(articles[\"created_at_ts\"], unit=\"ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "gather": {
     "logged": 1745764160505
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3) Combine train + validation\n",
    "train_plus_val = pd.concat([train_df, val_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "gather": {
     "logged": 1745764172579
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4) Compute scores with best hyperparameters (h=3 days, β=0)\n",
    "cands = compute_scores(\n",
    "    train_plus_val,\n",
    "    articles,\n",
    "    half_life_days=3,\n",
    "    beta=0.0,\n",
    "    fresh_window_days=FRESH_WINDOW_DAYS,\n",
    "    top_m=TOP_M\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "gather": {
     "logged": 1745764239026
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Recall@10 (h=3, β=0): 0.1211\n"
     ]
    }
   ],
   "source": [
    "# 5) Evaluate on test set\n",
    "test_recall = recall_at_k(cands, articles, test_df, RECALL_K)\n",
    "print(f\"Final Test Recall@{RECALL_K} (h=3, β=0): {test_recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python (p9-recsys)",
   "language": "python",
   "name": "p9-recsys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
